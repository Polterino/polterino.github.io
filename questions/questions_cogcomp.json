[
    {
        "question": "According to Bayesian inference",
        "options": ["the posterior probability is proportional to the likelihood multiplied by the prior", 
					"the amount of observed data does not influence the estimate of the posterior",
					"the prior probability should be uniform",
					"the normalization factor represents the likelihood of the data",
					"the posterior probability can be estimated using maximum-likelihood"],
        "correctAnswer": 0,
        "verified": 1
    },
	{
        "question": "Intercausal reasoning in Bayesian networks updates the estimate of a variable",
        "options": ["using information from the parents of its children",
					"using information from its parents",
					"using information from the variables in the Markov blanket",
					"using an iterative procedure",
					"using information from its children"],
        "correctAnswer": 0,
        "verified": 1
    },
    {
        "question": "A universal computing machine",
        "options": ["approximates a Turing machine with a neural network",
					"can solve the symbol grounding problem through inductive inference",
					"is an ideal computing machine with continuous states",
					"is a theoretical device that can simulate any algorithm",
					"can simulate any algorithm using a finite amount of memory"],
        "correctAnswer": 3,
        "verified": 1
    },
	{
        "question": "According to Innatism",
        "options": ["most of our knowledge is present at birth",
					"mental states are completely determined by brain states",
					"the nature of our knowledge is probabilistic",
					"we can generalize the property of a population from the property of a sample",
					"a rational agent can select the best action regardless of the sensory evidence"],
        "correctAnswer": 0,
        "verified": 1
    },
    {
        "question": "The emergentist approach for modeling cognition",
        "options": ["emphasizes the central role of deductive reasoning in knowledge discovery",
					"is based on explicit knowledge representations",
					"argues that thinking arises from the activation dynamics of neuronal networks",
					"argues that cognition can be programmed using syntactic rules",
					"argues that intelligence can be programmed in a universal computing machine"],
        "correctAnswer": 2,
        "verified": 0
    },
	{
        "question": "The <u>algorithmic</u> level in Marr's \"three levels of analysis\"",
        "options": ["describes how the computation can be physically implemented",
					"describes the goal of the computation",
					"describes the goal of the computation and how inputs and outputs are represented",
					"describes the goal of the algorithm and how it can be implemented",
					"describes the representation for the input and the output of the model"],
        "correctAnswer": 4,
        "verified": 1
    },
	{
        "question": "In order to adjudicate between competing theories",
        "options": ["we should choose the simpler model",
					"we should choose the most transparent model",
					"verbal theories should be preferred over black-box models",
					"we should choose the model with better descriptive adequacy",
					"we should use strong inference to test the transparency of the model"],
        "correctAnswer": 3,
        "verified": 1
    },
	{
        "question": "In emergentist cognitive models",
        "options": ["it is easier to attribute a meaning to each representatonal unit",
					"we assume that knowledge and reasoning are separate processes",
					"knowledge is represented in a declarative form",
					"knowledge is represented explicitly",
					"knowledge is represented by a vector of activations over basic processing units"],
        "correctAnswer": 4,
        "verified": 0
    },
	{
		"question": "Elman networks",
        "options": ["use as context the previous state of the output layer",
					"use a context layer to learn spatial representations",
					"use as context the previous state of the hidden layer",
					"use lateral connections to process temporal information",
					"use bidirectionals connections between Internal output units"],
        "correctAnswer": 2,
        "verified": 1
	},
	{
		"question": "In reinforcement learning",
        "options": ["the goal is to discover a causal model of the environment",
					"the goal is to maximize the value function",
					"the environment can be defined as a Markov Decision Process",
					"the agent learns from trial and error",
					"the goal is to maximize the control policy"],
        "correctAnswer": 3,
        "verified": 1
	},
	{
		"question": "How can we factorize the joint distribution for the following Bayesian network?",
        "options": ["P(A,B,C,D,E) = P(A,B)P(C,D)P(E)",
					"P(A,B,C,D,E) = P(A)P(B)P(C|A,B) P(D)P (E|C)",
					"P(A,B,C,D,E) = P(A)P(B|D)P(C|A,B)P(D)P(E|C)",
					"P(A,B,C,D,E) = P(A)P(B|D)P(C|A,B)P(C,E)",
					"P(A,B,C,D,E) = P(A|C)P(B|C)P(D|B)P(C|E)"],
        "correctAnswer": 2,
		"image": "img/domanda.png",
        "verified": 1
	},
	{
		"question": "How can we factorize the joint distribution for the following Bayesian network?",
        "options": ["P(A,B,C,D) = P(A)P(B)P(C)P(D)",
					"P(A,B,C,D) = P(A|B,C,D)P(B)P(C)P(D|C,A)",
					"P(A,B,C,D) = P(A)P(B)P(C|A,D)",
					"P(A,B,C,D) = P(A)P(B|A)P(C|A,D)P(D|A)",
					"P(A,B,C,D) = P(A,B)P(A,C,D)"],
        "correctAnswer": 3,
		"image": "img/factorize2.png",
        "verified": 1
	},
	{
		"question": "In the delta rule, the weight changes are given",
        "options": ["by the mean squared error between desired output and network output",
					"by the difference between target and output, multiplied by the input",
					"by the difference between target and output, multiplied by the gradient",
					"by the difference between input and output",
					"by the difference between target and output, multiplied by the bias"],
        "correctAnswer": 1,
        "verified": 1
	},
	{
		"question": "In a restricted Boltzmann machine",
        "options": ["during the positive phase visible units are reconstructed",
					"lateral connections are present only in the hidden layer",
					"contrastive divergence is used to minimize the classification error",
					"units in the same layer are statistically independent",
					"activations of all units within a layer can be computed at the same time"],
        "correctAnswer": 4,
        "verified": 1
	},
	{
		"question": "We have a conjugate prior",
        "options": ["when the prior distribution is in the same hypothesis space of the likelihood",
					"when the likelihood function is Gaussian",
					"when the prior distribution is Gaussian",
					"when the prior distribution is uniform",
					"when the posterior distribution is in the same family as the prior distribution"],
        "correctAnswer": 4,
        "verified": 1
	},
	{
		"question": "Gibbs sampling",
        "options": ["generate random samples consistent with the evidence",
					"is an exact inference procedure for Bayesian networks",
					"exploits the Markov blanket to discard samples that are not consistent with the evidence",
					"use a Markov chain to iteratively approximate the target distribution",
					"exploits the Markov blanket to sample conditionally dependent variables at the same time"],
        "correctAnswer": 3,
        "verified": 1
	},
	{
		"question": "In the formal neuron, the signals coming from other neurons are",
        "options": ["multiplied by the threshold",
					"multiplied by the synaptic weights and then subtracted",
					"subtracted to the average activation",
					"multiplied by the synaptic weights and then summed",
					"added to the synaptic weights using a sigmoid activation function"],
        "correctAnswer": 3,
        "verified": 1
	},
	{
		"question": "What distinguishes a multilayer feed-forward network from a perceptron?",
        "options": ["the linear separability of the input patterns",
					"the ability to learn pattern association",
					"the use of the delta rule",
					"the ability to learn non-linear functions",
					"the use of the Hebb rule"],
        "correctAnswer": 3,
        "verified": 1
	},
	{
		"question": "In Boltzmann machines, during the <u>positive</u> phase",
        "options": ["correlations are computed between hidden units and model reconstructions",
					"the hidden units are clamped to the previous state",
					"both visible and hidden units can change their activation",
					"only hidden units can change their activation",
					"Gibbs sampling is used to reconstruct the input data"],
        "correctAnswer": 3,
        "verified": 1
	},
	{
		"question": "In Boltzmann machines, during the <u>positive</u> phase",
        "options": ["both visible and hidden units can change their activation",
					"only hidden units can change their activation",
					"correlations are computed between all hidden units",
					"the visible units are clamped to the input data",
					"the hidden units are clamped to the previous input data"],
        "correctAnswer": 1,
        "verified": 1
	},
	{
		"question": "A deep belief network",
        "options": ["learns a sequential generative model",
					"use the top-down connection to propagate the error gradients",
					"is formed by hierarchy of linear layer",
					"is formed by hierarchy of stochastic networks",
					"requires training labels that express probabilities"],
        "correctAnswer": 3,
        "verified": 1
	},
	{
		"question": "Descriptive adequacy is",
        "options": ["the accuracy of the empirical data so that is suitable for modeling",
					"a transparent description of the data and the models",
					"the accuracy of the model in predicting the dataset",
					"the accuracy in describing the model architecture and parameters",
					"the accurate description and justification of all model assumptions"],
        "correctAnswer": 2,
        "verified": 1
	},
	{
		"question": "According to empiricism",
        "options": ["we are born with innate ideas and concepts",
					"in order to understand human intelligence we need to conduct psycological experiments",
					"there is a clear distinction between mental processes and physical processes",
					"knowledge is discovered primarly by deduction",
					"most of our knowledge is derived by sensory experience"],
        "correctAnswer": 4,
        "verified": 1
	},
	{
		"question": "in structured cognitive models",
        "options": ["knowledge is embedded in the connection weights of a neural network",
					"concepts are represented in a distributed fashon",
					"the topology of the computational graph is usually learned from the data",
					"each hypothesis is represented by a vector of activations over basic processing units",
					"we assume that knowledge and reasoning are separate processes"],
        "correctAnswer": 4,
        "verified": 1
	},
	{
		"question": "The actual weights update in NN learning",
        "options": ["correspond to the derivative of the activation function",
					"should be initialized to random values at the beginning of learning",
					"should be small to obtain a faster learning",
					"should be scaled down to avoid deletion of previously learned knowledge",
					"are equal to the gradient of the cost function"],
        "correctAnswer": 3,
        "verified": 0
	},
	{
		"question": "the symbolic approach for modelling cognition",
        "options": ["argues that thinking can be simulated in a universal machine",
					"argues that simulating intelligence requires to understand the details of the brain",
					"is based on implict knowledge representations",
					"emphatizes the central role of learning in knowledge development",
					"argues that cognition cannot be programmed using syntactic rules"],
        "correctAnswer": 0,
        "verified": 1
	},
	{
		"question": "according to the Turing test, a machine can be considered intelligent if",
        "options": ["it can be programmed to manipulate mathematical expressions",
					"it's able to solve challenging tasks, such as playing chess or Go",
					"it's over behavior is undistinguishable from that of a human being",
					"it's internal functioning replicates the details of a human brain",
					"it can be implemented in a real robot"],
        "correctAnswer": 2,
        "verified": 1
	},
	{
		"question": "the vanishing gradient problem in deep network",
        "options": ["can be solved using ReLU neurons",
					"can be solved using dropout",
					"can be solved using sigmoid neurons",
					"can be solved using sparse connectivity",
					"can be solved using weight sharing"],
        "correctAnswer": 0,
        "verified": 1
	},
	{
		"question": "Rejection sampling",
        "options": ["discard samples that are not consistent with the evidence",
					"only generates samples consistent with the evidence",
					"expoints the markov blanket of a node to iteratively refine the estimated values",
					"allows to implement exact inference using variable elimination",
					"is an efficient inference procedure for bayesian network"],
        "correctAnswer": 0,
        "verified": 1
	},
	{
		"question": "Long Short Term Memory networks",
        "options": ["exploit the vanishing gradient to learn long range temporal dependencies",
					"simulates the memorization of temporal informations in the hippocampus",
					"exploit a seq-to-seq architecture to memorize informations",
					"use gated units to regulate the flow of informations",
					"map an entire sequence into a variable-length vector"],
        "correctAnswer": 3,
        "verified": 1
	},
	{
		"question": "In bayesian network the markov blanket of a node contains",
        "options": ["the parents, the children, and the parent of the children",
					"the set of nodes that, when observed, makes a node correlated to all the others",
					"the set of directly connected nodes",
					"the parent nodes",
					"the children nodes"],
        "correctAnswer": 0,
        "verified": 1
	},
	{
		"question": "In a Markov network, the Markov blanket of a node contains",
        "options": ["the parent, children and children of the children nodes",
					"the set of nodes that, when observed, makes a node correlated to all the others",
					"the set of directly connected nodes",
					"the parent nodes",
					"the children nodes"],
        "correctAnswer": 2,
        "verified": 1
	},
	{
		"question": "in the <u>computational</u> level in marr's \"three level of analysis\"",
        "options": ["describes the algorithm that can achieve the goal",
					"describes the goal of the computation and why it is appropriate",
					"describes the goal of the algorithm and how it can be implemented",
					"describes the goal of the computation and how inputs and outputs are represented",
					"describes how the computation can be implemented"],
        "correctAnswer": 1,
        "verified": 1
	},
	{
		"question": "Which method promotes good generalization in a neural network?",
        "options": ["using decay of the bias",
					"using a small learning rate",
					"performing a prolonged training",
					"using cross-validation to tune the loss function",
					"using a small number of hidden units"],
        "correctAnswer": 4,
        "verified": 1
	},
	{
		"question": "In convolutional neural networks",
        "options": ["pooling layers are used to simulate the connectivity of a rectangular neighborhood",
					"the goal is to learn a generative model of the data",
					"pooling layers are used to reduce the dimensionality of receptive fields",
					"neurons have local receptive fields",
					"the number of layers depends on the size of the input"],
        "correctAnswer": 3,
        "verified": 1
	},
	{
		"question": "the chinese room experiment",
        "options": ["proposes a solution to the symbol grounding problem",
					"argues that syntactic manipulations can lead to semantic content",
					"argues that displaying the correct behavior does not imply understanding",
					"can be used to establish if a machine could pass the turing test"],
        "correctAnswer": 2,
        "verified": 1
	},
	{
		"question": "In hierarchical generative models",
        "options": ["we use deep belief network to approximate a linear function",
					"the system learns an internal model of the world in a discriminative way",
					"bottom up processing can support perceptual inference over ambiguous input",
					"top down processing is separate from learning",
					"different variables can share the same prior"],
        "correctAnswer": 4,
        "verified": 0
	},
	{
		"question": "two random variable are statistically independent",
        "options": ["the joint distribution corresponds to the product of their individual distributions",
					"the joint distribution corresponds to the sum of their individual distributions",
					"the conditional distribution can be factorized using the same prior",
					"the joint distribution is defined by a fully connected graph",
					"they can be represented using a direct graph"],
        "correctAnswer": 0,
        "verified": 1
	},
	{
		"question": "inductive reasoning",
        "options": ["assumes that we can infer general properties from sample evidences",
					"does not support analogical inference",
					"allows to enstablish whether an argument is true or false",
					"does not support causal inference",
					"is based on logical deduction"],
        "correctAnswer": 0,
        "verified": 1
	},
	{
		"question": "The backpropagation algorithm",
        "options": ["is an extension of the delta rule used to train single-layer networks",
					"can only be applied when the activation function is continuous",
					"propagates the classification error through a separate set of backward connections",
					"cannot learn the XOR problem",
					"can approximate non-linear functions through unsupervised learning"],
        "correctAnswer": 0,
        "verified": 1
	},
	{
		"question": "In probabilistic programming",
        "options": ["we use computer programs to represent and manipulate neural network models",
					"we represent uncertainty as a conditional probability distribution",
					"we can exploit Bayesian inference to estimate the program parameters",
					"we can use recursion and control flow statements to speed-up inference",
					"learning consists of constructing programs that best explain the likelihood of the data"],
        "correctAnswer": 2,
        "verified": 0
	},
	{
		"question": "Large-scale neural language models",
        "options": ["can produce word embeddings that capture the semantic of language",
					"need to exploit positional encoding to preserve the order of the elements",
					"assume that each token depends only on the previous n-1 tokens",
					"can learn word representation using n-grams",
					"need exploit attention mechanisms to discover lexical categories"],
        "correctAnswer": 1,
        "verified": 0
	},
	{
		"question": "Large-scale neural language models",
        "options": ["use variable-length vectors as word embeddings",
					"need to exploit positional encoding to preserve the order of the elements",
					"assume that each token depends only on the previous n-1 tokens",
					"can learn word representation using n-grams",
					"need exploit attention mechanisms to discover lexical categories"],
        "correctAnswer": 1,
        "verified": 0
	},
	{
		"question": "The complementary learning systems theory suggests that",
        "options": ["catastrophic interference is due to similarity weighted interleaved learning",
					"there are separate memory systems in the neocortex",
					"the neocortex slowly learns sparse representations of the data",
					"the hippocampus rapidly learns new semantic information",
					"interleaved learning can take advantage of generative replay"],
        "correctAnswer": 4,
        "verified": 0
	},
	{
		"question": "Connection weights in a classic multy-layer perceptron",
        "options": ["are gradually modified to solve the interference problem",
					"encode short-term semantic memory",
					"are gradually modified to encode episodic memory",
					"enable the use of working memory during statistical inference",
					"are gradually tuned to represent statistical regularities"],
        "correctAnswer": 4,
        "verified": 1
	},
	{
		"question": "Long-term memory in artificial neural networks",
		"options": ["is encoded in the hidden neurons activations",
					"is based on a fast semantic learning process",
					"exploits distributed representations to avoid catastrophic interference",
					"is encoded by gradually tuning connection weights",
					"is encoded by connection weights that represent individual learning episodes"],
		"correctAnswer": 3,
        "verified": 0
	},
	{
		"question": "The complementary learning systems theory suggests that",
		"options": ["fast learning of new information requires pattern separation",
					"catastrophic interference is due to sparse coding in the hippocampus",
					"episodic information is encoded by distributed representation in the hippocampus",
					"slow learning of old information requires sparse coding",
					"fast learning of new information requires pattern completion"],
		"correctAnswer": 0,
        "verified": 1
	},
	{
		"question": "Strong inference testing",
		"options": ["can improve transparency of black-box models",
					"establishes whether a model has good descriptive adequacy",
					"is based on the assumption that simpler models should be preferred",
					"allows to adjudicate between competing models through falsification",
					"allows to test the statistical validity of a null hypothesis"],
		"correctAnswer": 3,
        "verified": 0
	},
	{
		"question": "Catastrophic forgetting in artificial neural networks",
		"options": ["is due to the overlapping nature of distributed representations",
					"can be mitigated using continual learning",
					"can be mitigated by decreasing the learning rate",
					"is partially due to the vanishing gradient problem",
					"can be solved using sparse representation in the neocortex"],
		"correctAnswer": 0,
		"motivation_image": "img/cogcomp/correct1.png",
        "verified": 1
	},
	{
		"question": "In probabilistic programming",
        "options": ["we can estimate the value of the program parameters using gradient descent",
					"we define a computer program with stochastic behavior",
					"we use computer programs to represent probabilistic models",
					"the output of the algorithm is always a probability distribution",
					"we exploit graphical models to perform Bayesian inference"],
        "correctAnswer": 2,
        "motivation_image": "img/cogcomp/correct1.png",
        "verified": 1
	},
	{
		"question": "In Boltzmann machines, during the <u>negative</u> phase",
		"options": ["both visible and hidden units can change their activation",
					"only hidden units can change their activation",
					"correlations are computed between all hidden units",
					"the visible units are clamped to the input data",
					"the hidden units are clamped to the previous input data"],
		"correctAnswer": 0,
        "verified": 1
	},
	{
		"question": "According to Cartesian dualism",
		"options": ["we should adopt an emergentist view of cognition",
					"the world is immaterial",
					"conscious thinking is generated by the brain",
					"mental phenomena can be distinguished from material phenomena",
					"mental and physical processes are essentially the same thing"],
		"correctAnswer": 3,
        "verified": 0
	}
]
